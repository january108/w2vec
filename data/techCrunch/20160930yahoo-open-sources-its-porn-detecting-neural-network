Yahooがポルノを検出するニューラルネットワークをオープンソース化、ただし訓練はあなたの仕事インターネットの上のものに、どうやってNSFWを指定するのか？　Yahooに聞こう。Yahooはそれをやっている。わいせつなコンテンツで訓練した、同社特製の、ポルノ検出ニューラルネットワークだ。そして今回、そのシステムがオープンソースになったから、誰もが使える。そう、そのとおり、フォークするのも自由だ。それはもちろん冗談。Yahooのアルゴリズムは万能ではない。画像を見てNSFWだ、と判断するのは、もっとも手強い難問の一つだ。昔から、見れば分かるさと誰もが言うが、そう言える人は、全生涯をポルノを見て過ごした人だけだ。コンピューターには、そんな経験はない。 Senator calls for SEC investigation into Yahoo breach
NYC public internet kiosk tablets have disabled, because people obviously used them for porn
Google open sources image captioning model in TensorFlow
純潔無知なマシンもしかし、Yahooに捕まって何千もの画像で訓練され、画像認識エンジンにされてしまうと、腐敗のきわみに達する。もう、彼の純情は永遠に盗まれてしまった。しかしそれと引き換えに、あなたがネットで検索したとき、結果にいやらしいものが紛れ込む確率は低くなる。でも、まじめな話、畳み込みニューラルネットワーク(convolutional neural networks, CNN)は画像を分類するための優れたツールだ。そのことは、これまでの数多い研究によって証明されている。特定のタイプの画像のデータベースで訓練すると、アルゴリズムは一定のパターンに対して敏感になる。犬を見分けるCNNなら、尻尾や鼻や、とがった口をたくさん見せられるだろう。車なら、車輪やドアの取っ手やラジエーターグリルを認識する。そしてポルノなら何を、…それはご想像におまかせしよう。Yahooのシステムはいろんな画像を見て、それらに0から1までの点をつける。ポルノだと判断した画像の点は、1に近い。検閲目的だけでなく、いろんな状況で使えそうだ。刺激的な画像が歓迎される場面もあるが、Web上の大量のデータを相手にするときは、それらを篩い落とせた方が便利だ。メールやメッセージを、プライバシー侵害にならずに、チェックすることもできる。同僚がいたずらで送ってきたNSFW画像を、職場でうっかり開く醜態は、たぶんなくなる。オープンソースのコードをビルドしてエンジンができても、まだそれは全然訓練されていない。たくさんポルノを見せて訓練するのは、あなたの役目だ。でも今のインターネットの上なら、それは問題ないだろう。詳しい説明はYahooのブログ記事にある。そしてコードのダウンロードはGitHubからだ。