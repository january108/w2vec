両義的な文の機械翻訳で正しい訳語をガイドするGoogleのTransformerシステム機械学習が翻訳にも大きく貢献することが実証されてきたが、弱点もある。たとえば翻訳モデルには、逐語主義（一語々々仕事をしていく）という性癖があり、それが深刻なエラーに導くこともある。Google Researchの今日（米国時間8/31）のブログ記事が、この問題の性質と、それに対する解決方法を詳述している。同社の自然言語処理の部署にいるJakob Uszkoreitが、問題をうまく説明している。次のような二つのセンテンスがあるとしよう:I arrived at the bank after crossing the street.I arrived at the bank after crossing the river.もちろん、これらの“bank”の意味は同じではない。でも、その意味はセンテンスを最後まで読まないと分からないから、アルゴリズムはこの語を拾ったとき間違った訳を与えるかもしれない。いろんな文章を注意して読むと、このような曖昧性は至るところにあることに気づく。ぼくならセンテンスを書き換えるが（StrunkとWhiteはこれについて警告している）、もちろんそれは翻訳システムの能力にはない。また、このような曖昧なケースのすべてに対応できるように、ニューラルネットワークの振る舞いを変えることも、たいへんすぎて非現実的だ。Googleのソリューションは、Attention Mechanismと呼ばれる。同社はそれを、Transformerと名付けたシステムへ実装した。それはセンテンス中の各語をすべてのその他の語と比較して、お互いのあいだにどれぐらい重要な影響関係があるか調べる。たとえば、“he”が話しているのか、“she”が話しているのか、それとも“bank”のような語に特別の意味があるのか…。訳文を構築するとき、Attention Mechanismは各語を、他のすべての語の末尾につけた形で比較する。下のGIF画像は、その様子を表している。…ある程度はね。今週のこの記事〔未訳〕を読まれた方は、すでにAttention Mechanismの用例をご存知だろう。その記事では協同ファウンダーが、この問題にはいちばん苦労した、と言っている。そして、Googleのポストが参考にしているコーネル大学のペーパーも教えてくれた。もちろん、Googleがそのペーパーの記述を模倣しているわけではない。しかしDeepLの実装はとても効果的で、Googleのよりも良いかもしれない。Googleのやり方には、面白い副作用があって、システムのロジックをのぞき見できる: Transformerは各語に、すべてのほかの語との関連性をスコア（得点）で与える。下図では色の濃淡がスコアだが、左のセンテンスではitはanimalとの関連性が濃く、右のセンテンスではitはstreetとの関連性が濃い: 〔tired（疲れている）のはanimal、wid（広い）のはstreetだ〕これは、うまいやり方だよね。少なくともぼくは、そう思う。この例では“it”がstreetかanimalかに関して曖昧性があり、最後の語を知らないとどっちが正しいか分からない。人間は教わらなくても分かるが、機械には、何でも教えなければならないのだ。