一歳を迎えたGoogleのTPUチップがアップグレード、機械学習/ディープラーニングのすそ野をさらに広げるGoogleが今日（米国時間5/17）のGoogle I/Oカンファレンスで、同社特製の機械学習チップTensor Processing Unit(TPU)の次世代バージョンを発表した。この、機械学習のタスクを高速化する専用チップは、従来のCPUやGPUよりも速いとされているが、昨年の同カンファレンスで発表されて以来、今回が初めてのアップグレードになる。まず、スピードのアップだ。Googleによると、第二世代のTPU（‘Cloud TPU’）は1基が180TFLOPSの性能を有する。まだベンチマークは見ていないが、スピード以外でも進歩している。第一世代のTPUは既存のモデルを使って推論するだけだが、第二世代はモデルの訓練もできる。モデルの訓練は機械学習のワークフローの中でもとくに重要だが、その全過程をこの強力なチップがやってしまうのだ。機械学習のモデルとは、たとえば写真に写っているものが木か車か猫かを正しく同定する能力のことだ。機械学習の推論とは、モデルを使って行う確率つきのオブジェクト同定処理だ。たとえば、“この写真に写っているのは85%の確率で木であってブロッコリの茎ではない”、などと推論する。Googleの今日の声明文によると、同社の大規模な翻訳用のモデルを訓練するのに、市販の最良のGPU 32基を使用してまる一日、その1/8の台数の“TPUポッド”〔64TPUs, 11.5PFLOPS〕では午後の数時間で完了した、という。