Facebookの視覚障害者用画像説明ツールがまずiOSでローンチ、独自のオブジェクト認識技術を使用Facebookが、視覚障害者に同サイト上の画像が“わかる”ためのツールAutomatic Alternative Text（ALTテキスト自動生成）をローンチした。画面上に何が表示されているのか知りたい人のためにATTは、オブジェクト認識技術を使って、Facebook上の写真の説明文を生成する。このツールは、Facebookのアクセシビリティチーム（上図）が数か月かけて作った。Facebookの初めての視覚障害者の技術者であるMatt Kingが、昨年10月に次のように語った: “ニューズフィードのどれぐらいにビジュアルがあるだろうか。たぶん、ほとんどのニュースにあるだろう。コメントも、写真に関するものが多いし、ニュースをポストする人も写真について何か言ってることが多い。でもそんなテキストからは、その写真に何が写ってるのか分からないね。ぼくみたいな者にとっては、そこで何が行われているのか、何について話しているのか、それを知りたいんだけどね”。ATTの前には、その写真を共有している人の名前は聞けた。Facebookに写真を投稿した人の、写真に関する説明文も聞けた。しかしATTなら、“画像には戸外で三人の人が写っていて微笑（ほほえ）んでいる”、といったテキストを聞ける。このFacebookのATTを駆動しているオブジェクト認識技術は、パラメータの数が何百万もあるニューラルネットワークを、何百万ものオブジェクトで訓練したものを使っている。ニューラルネットワークは、機械学習の基本形式の一つだ。画像認識の場合、ニューラルネットワークはパターン認識システムだ、と考えればよい。ATTが使っているFacebookの技術は、画像と言葉をいくつかのカテゴリーに分類しながら認識する:・交通（自動車、ボート、オートバイ、などなど）
・自然（アウトドア、山、波、太陽、草、などなど）
・スポーツ（テニス、水泳、スタジアム、などなど）
・食品（アイスクリーム、寿司、デザート、などなど）また、物の外見を説明する語として、（赤ちゃん、眼鏡、微笑んでいる、宝石、セルフィー、などなど）も使用する。AATが今対応しているのはiOSの画面のみ、言語は英語のみだ。視覚障害者のFacebook利用は、iOSデバイス上がいちばん多い。ただしもちろん、今後はほかのプラットホームや言語にも対応していく。ATTが実際に使われている様子を、下のビデオでご覧いただこう。